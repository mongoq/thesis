{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPTsz+De4KfHtmyMK6bx51J",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mongoq/thesis/blob/main/Systemrelevant.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**GPUs in use**"
      ],
      "metadata": {
        "id": "P7lO0XCY_Fza"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "23TOba33L4qf",
        "outputId": "c8111723-863b-4432-d1a9-aa4aad7a75bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon Sep 19 21:34:13 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   39C    P0    25W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n",
            "\n",
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2020 NVIDIA Corporation\n",
            "Built on Mon_Oct_12_20:09:46_PDT_2020\n",
            "Cuda compilation tools, release 11.1, V11.1.105\n",
            "Build cuda_11.1.TC455_06.29190527_0\n",
            "\n",
            "\n",
            "==============NVSMI LOG==============\n",
            "\n",
            "Timestamp                                 : Mon Sep 19 21:34:13 2022\n",
            "Driver Version                            : 460.32.03\n",
            "CUDA Version                              : 11.2\n",
            "\n",
            "Attached GPUs                             : 1\n",
            "GPU 00000000:00:04.0\n",
            "    Temperature\n",
            "        GPU Current Temp                  : 39 C\n",
            "        GPU Shutdown Temp                 : 85 C\n",
            "        GPU Slowdown Temp                 : 82 C\n",
            "        GPU Max Operating Temp            : N/A\n",
            "        GPU Target Temperature            : N/A\n",
            "        Memory Current Temp               : N/A\n",
            "        Memory Max Operating Temp         : N/A\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[name: \"/device:CPU:0\"\n",
              " device_type: \"CPU\"\n",
              " memory_limit: 268435456\n",
              " locality {\n",
              " }\n",
              " incarnation: 2687108578271242749\n",
              " xla_global_id: -1, name: \"/device:GPU:0\"\n",
              " device_type: \"GPU\"\n",
              " memory_limit: 16139419648\n",
              " locality {\n",
              "   bus_id: 1\n",
              "   links {\n",
              "   }\n",
              " }\n",
              " incarnation: 2510580416648594306\n",
              " physical_device_desc: \"device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\"\n",
              " xla_global_id: 416903419]"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU\\n')\n",
        "else:\n",
        "  print(gpu_info)\n",
        "\n",
        "print('')\n",
        "!/usr/local/cuda/bin/nvcc --version\n",
        "print('')\n",
        "\n",
        "!nvidia-smi -q -d TEMPERATURE\n",
        "\n",
        "from tensorflow.python.client import device_lib\n",
        "device_lib.list_local_devices()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ram supply**"
      ],
      "metadata": {
        "id": "POSCRuOq_eEQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V1G82GuO-tez",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "684ea0e4-d315-409d-8b6f-c85b7c12f17e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your runtime has 13.6 gigabytes of available RAM\n",
            "\n",
            "Not using a high-RAM runtime\n",
            "\n",
            "MemTotal:       13297228 kB\n",
            "MemFree:        10493292 kB\n",
            "MemAvailable:   12351904 kB\n",
            "Buffers:           87228 kB\n",
            "Cached:          1894452 kB\n",
            "SwapCached:            0 kB\n",
            "Active:           665244 kB\n",
            "Inactive:        1957020 kB\n",
            "Active(anon):        980 kB\n",
            "Inactive(anon):   563272 kB\n",
            "Active(file):     664264 kB\n",
            "Inactive(file):  1393748 kB\n",
            "Unevictable:           0 kB\n",
            "Mlocked:               0 kB\n",
            "SwapTotal:             0 kB\n",
            "SwapFree:              0 kB\n",
            "Dirty:              1008 kB\n",
            "Writeback:             0 kB\n",
            "AnonPages:        640744 kB\n",
            "Mapped:           272260 kB\n",
            "Shmem:              1264 kB\n",
            "KReclaimable:      84100 kB\n",
            "Slab:             114388 kB\n",
            "SReclaimable:      84100 kB\n",
            "SUnreclaim:        30288 kB\n",
            "KernelStack:        5760 kB\n",
            "PageTables:        13584 kB\n",
            "NFS_Unstable:          0 kB\n",
            "Bounce:                0 kB\n",
            "WritebackTmp:          0 kB\n",
            "CommitLimit:     6648612 kB\n",
            "Committed_AS:    3685628 kB\n",
            "VmallocTotal:   34359738367 kB\n",
            "VmallocUsed:       10628 kB\n",
            "VmallocChunk:          0 kB\n",
            "Percpu:             1400 kB\n",
            "HardwareCorrupted:     0 kB\n",
            "AnonHugePages:         0 kB\n",
            "ShmemHugePages:        0 kB\n",
            "ShmemPmdMapped:        0 kB\n",
            "FileHugePages:         0 kB\n",
            "FilePmdMapped:         0 kB\n",
            "CmaTotal:              0 kB\n",
            "CmaFree:               0 kB\n",
            "HugePages_Total:       0\n",
            "HugePages_Free:        0\n",
            "HugePages_Rsvd:        0\n",
            "HugePages_Surp:        0\n",
            "Hugepagesize:       2048 kB\n",
            "Hugetlb:               0 kB\n",
            "DirectMap4k:      103232 kB\n",
            "DirectMap2M:     5136384 kB\n",
            "DirectMap1G:    10485760 kB\n"
          ]
        }
      ],
      "source": [
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('Not using a high-RAM runtime')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')\n",
        "print('')\n",
        "\n",
        "!cat /proc/meminfo"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Google Drive**"
      ],
      "metadata": {
        "id": "ZlX97Xb-_0DY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "!ls /content/drive/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xxu49OfHAE8j",
        "outputId": "4426884e-a50a-4cec-d4a2-82d39609b447"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            " All-App-Inventor-Projects.zip\t Skin_Cancer.sav\n",
            "'Colab Notebooks'\t\t Training_gesichert_4.9.22\n",
            "'Google Earth'\t\t\t'Unbenanntes Dokument.gdoc'\n",
            " ham10000-dataset\t\t'Unbenannte Tabelle (1).gsheet'\n",
            " ISIC_0024306_nv.jpg\t\t'Unbenannte Tabelle.gsheet'\n",
            " skin-cancer-mnist-ham10000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Pina Programmiert**\n",
        "\n",
        "https://www.heise.de/hintergrund/Google-Colab-Wie-Sie-Python-Skripte-mit-Eingabefeldern-anpassen-7142452.html?seite=all"
      ],
      "metadata": {
        "id": "cIDYSjYXAKoP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pinas_marktwert = 15   #@param{type:\"slider\", min:0, max:100, step:5}\n",
        "pina_kanns = True   #@param{type: \"boolean\"}\n",
        "if pina_kanns==True:\n",
        "  print('Pina kann Programmieren mit', pinas_marktwert, 'Punkten')\n",
        "else:\n",
        "  print('Pina bringts nicht mit', pinas_marktwert, 'Punkten')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cyRlTmQgASKZ",
        "outputId": "5adf1044-7e7b-4ba5-d500-411b48b38747"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pina kann Programmieren mit 15 Punkten\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Java**\n",
        "\n",
        "https://colab.research.google.com/github/deepjavalibrary/d2l-java/blob/colab/chapter_deep-learning-computation/use-gpu.ipynb#scrollTo=3Fd1cYVXDHDC"
      ],
      "metadata": {
        "id": "rxAFU2AgENiX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**OpenCV** with youtube"
      ],
      "metadata": {
        "id": "mVUXe7Ylq68r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO"
      ],
      "metadata": {
        "id": "8iaDx5qxq6WY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}