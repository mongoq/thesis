{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNWEJvT2GTXm4ZrM+EF/NCT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mongoq/thesis/blob/main/Classic_Motorway_4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Source: https://towardsdatascience.com/implementing-real-time-object-detection-system-using-pytorch-and-opencv-70bac41148f7"
      ],
      "metadata": {
        "id": "axOK8tBxlbLR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install pafy youtube-dl==2020.12.2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U0e4Kjecl3NF",
        "outputId": "c304ce66-78c0-419f-a0f5-aa4de6c34192"
      },
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pafy in /usr/local/lib/python3.7/dist-packages (0.5.5)\n",
            "Requirement already satisfied: youtube-dl==2020.12.2 in /usr/local/lib/python3.7/dist-packages (2020.12.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 129,
      "metadata": {
        "id": "UmSwhMPTilsy"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import pafy\n",
        "import youtube_dl\n",
        "import torch\n",
        "from time import time\n",
        "import numpy as np\n",
        "from torch import hub"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Detect():\n",
        "      #  Read this for classs magic:\n",
        "      #  https://cito.github.io/byte_of_python/read/class-and-object-vars.html\n",
        "\n",
        "      # Define Youtube videos \n",
        "      #_URL = \"https://www.youtube.com/watch?v=wqctLW0Hb_0\" # motorway traffic\n",
        "      _URL = \"https://www.youtube.com/watch?v=2sGTPMTaEcA\" # mein schÃ¶ner benz\n",
        "      _video_file = \"motorway.mp4\" # output file\n",
        "\n",
        "        #\"\"\"\n",
        "        #Load Yolo V5 Model and init the object\n",
        "        #\"\"\"\n",
        "      def __init__(self):\n",
        "        self.modeltorch = torch.hub.load( \\\n",
        "                      'ultralytics/yolov5', \\\n",
        "                      'yolov5s', \\\n",
        "                      pretrained=True)\n",
        "        #pass\n",
        "\n",
        "      # Define Video stream\n",
        "      def get_video_stream(self):\n",
        "        play = pafy.new(self._URL).streams[-1] #'-1' means read the lowest quality of video.\n",
        "        assert play is not None # we want to make sure there is a input to read.\n",
        "        stream = cv2.VideoCapture(play.url) #create a opencv video stream.\n",
        "        return stream\n",
        "\n",
        "        \"\"\"\n",
        "        The function below identifies the device which is availabe to make the prediction and uses it to load and infer the frame. Once it has results it will extract the labels and cordinates(Along with scores) for each object detected in the frame.\n",
        "        \"\"\"\n",
        "      #def score_frame(frame, model):\n",
        "      def score_frame(self, frame):\n",
        "        device = 'cpu' #'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "        #print(\"score_frame: modeltorch: \" + str(type(self.modeltorch)))\n",
        "        self.modeltorch.to(device)\n",
        "        #frame = [torch.tensor(frame)]\n",
        "        #print(\"Frame Typ vor Numpy\" + str(type(frame)) )\n",
        "        #--- > frame=[np.array(frame)]\n",
        "        #print(\"Frame Typ nach Numpy\" + str(type(frame)) )\n",
        "        #print(\"score_frame - frame Typ: \" + str(type(frame)))\n",
        "        #frame = torch.tensor(frame)\n",
        "        #frame = [int(torch.tensor(frame)).long()]\n",
        "        #print(\"score_frame frame \" + str(frame))\n",
        "        results = self.modeltorch(frame)\n",
        "        labels = results.xyxyn[0][:, -1].numpy()\n",
        "        cord = results.xyxyn[0][:, :-1].numpy()\n",
        "        #print(\"labels: \" + str(labels))\n",
        "        #print(\"cord: \" + str(cord))\n",
        "        return labels, cord\n",
        "\n",
        "        \"\"\"\n",
        "        The function below takes the results and the frame as input and plots boxes over all the objects which have a score higer than our threshold.\n",
        "        \"\"\"\n",
        "      def plot_boxes(self, results, frame):\n",
        "        labels, cord = results\n",
        "        n = len(labels)\n",
        "        print(\"Objects detected: \" + str(n))\n",
        "        x_shape, y_shape = frame.shape[1], frame.shape[0]\n",
        "        for i in range(n):\n",
        "          row = cord[i]\n",
        "          # If score is less than 0.2 we avoid making a prediction.\n",
        "          if row[4] < 0.2: \n",
        "            continue\n",
        "          x1 = int(row[0]*x_shape)\n",
        "          y1 = int(row[1]*y_shape)\n",
        "          x2 = int(row[2]*x_shape)\n",
        "          y2 = int(row[3]*y_shape)\n",
        "          bgr = (0, 255, 0) # color of the box\n",
        "          classes = self.modeltorch.names # Get the name of label index\n",
        "          label_font = cv2.FONT_HERSHEY_SIMPLEX #Font for the label.\n",
        "          cv2.rectangle(frame, \\\n",
        "                      (x1, y1), (x2, y2), \\\n",
        "                       bgr, 2) #Plot the boxes\n",
        "          cv2.putText(frame,\\\n",
        "                    classes[labels[i]], \\\n",
        "                    (x1, y1), \\\n",
        "                    label_font, 0.9, bgr, 2) #Put a label over box.\n",
        "        return frame\n",
        "\n",
        "        \"\"\"\n",
        "        The Function below oracestrates the entire operation and performs the real-time parsing for video stream.\n",
        "        \"\"\"\n",
        "      def __call__(self):\n",
        "        out_file= self._video_file # Define output file\n",
        "        player = self.get_video_stream() #Get your video stream.\n",
        "        assert player.isOpened() # Make sure that their is a stream. \n",
        "        #Below code creates a new video writer object to write our\n",
        "        #output stream.\n",
        "        x_shape = int(player.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "        y_shape = int(player.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "        four_cc = cv2.VideoWriter_fourcc(*\"MJPG\") #Using MJPEG codex\n",
        "        out = cv2.VideoWriter(out_file, four_cc, 20, \\\n",
        "                          (x_shape, y_shape)) \n",
        "        ret, frame = player.read() # Read the first frame.\n",
        "        while ret: # Run until stream is out of frames\n",
        "          start_time = time() # We would like to measure the FPS.\n",
        "          results = self.score_frame(frame) # Score the Frame\n",
        "          frame = self.plot_boxes(results, frame) # Plot the boxes.\n",
        "          end_time = time()\n",
        "          fps = 1/np.round(end_time - start_time, 3) #Measure the FPS.\n",
        "          #print(f\"FPS : {fps}\")\n",
        "          print(\"FPS: \" + str(fps.round(2)))\n",
        "          out.write(frame) # Write the frame onto the output.\n",
        "          ret, frame = player.read() # Read next frame."
      ],
      "metadata": {
        "id": "M7kGq7FIJ1G4"
      },
      "execution_count": 139,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Motorway=Detect()\n",
        "Motorway()"
      ],
      "metadata": {
        "id": "GaaBQ7eLtTu1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(Detect._video_file)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "qEYTsg8_X1wr",
        "outputId": "84075087-dbd8-4cb2-a89b-28b3d6c8a65c"
      },
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_1ab38603-1b93-4c12-b006-9d07a24014c3\", \"motorway.mp4\", 20306266)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}