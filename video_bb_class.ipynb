{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mongoq/thesis/blob/main/video_bb_class.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CA7e4DjwKh-S"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "np.set_printoptions(suppress=True)\n",
        "from urllib.request import Request, urlopen\n",
        "import urllib\n",
        "import time\n",
        "import os\n",
        "import traceback\n",
        "import pafy"
      ],
      "id": "CA7e4DjwKh-S"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "code_folding": [],
        "id": "1hRvuGiuKh-f"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Class Detection consists basically everything useful in this script. It has 4 methods(class functions): \n",
        "configure_net, detect, draw_img and keyboard. Those methods share a lot of parameters. \n",
        "Instead of returning 20 parameters from one function and passing them into next function, \n",
        "I decided to make a class that would store them as variables of a class instance.\n",
        "In __init__ I just wanted to give a heads up which variables exist and will be used by methods,\n",
        "but majority of them is filled not in __init__ but in one of those 4 methods.\n",
        "\"\"\"\n",
        "class Detection:\n",
        "    font = cv2.FONT_HERSHEY_PLAIN\n",
        "    colors = ((255,0,0), (0,255,0), (0,0,255), (255,255,0), (0,255,255), (255,0,255), (128,0,0)) \n",
        "    \n",
        "    def __init__(self, model_name = 'yolov3', input_height=416, path_yolo_classes='net/coco.txt', \n",
        "                 output_height=800, is_scale_output = True, MIN_confidence=0.5, IOU_threshold=0.6, \n",
        "                 is_blob_aspect_ratio=True, anchor_box_show=False, grid_show=False, show_text_on_box=True, \n",
        "                 is_recording=False, show_text_left=True):\n",
        "        self.model_name = model_name\n",
        "        self.net = None\n",
        "        self.anchors = None\n",
        "        \n",
        "        self.grids_per_height = round(input_height/32)\n",
        "        self.grids_per_width = self.grids_per_height\n",
        "        self.input_height = self.grids_per_height * 32\n",
        "        self.input_width = self.input_height\n",
        "        if input_height%32:\n",
        "            print('''Value of input_height={} is indivisible by 32, \n",
        "input_height={} will be used instead. \n",
        "Choose input_height that is an integer multiple of 32(eg.320,416,620,...).'''.format(input_height, \n",
        "                                                                                self.input_height))\n",
        "            \n",
        "        with open(path_yolo_classes, 'r') as f:\n",
        "            self.classes = f.read().splitlines()\n",
        "            \n",
        "        self.anchor_box_show = anchor_box_show\n",
        "        self.grid_show = grid_show   \n",
        "        self.show_text_on_box = show_text_on_box\n",
        "        self.show_text_left = show_text_left\n",
        "        self.is_recording = is_recording\n",
        "        self.is_any_frame_recorded = False\n",
        "        \n",
        "        self.MIN_confidence = MIN_confidence\n",
        "        self.IOU_threshold = IOU_threshold\n",
        "        self.FPS = 0.0\n",
        "       \n",
        "        self.img = None\n",
        "        self.img_name = None\n",
        "        self.img_with_drawings = None\n",
        "        self.img_height, self.img_width = None, None\n",
        "        self.boxes = None\n",
        "        self.confidences = None\n",
        "        self.best_class_ids = None\n",
        "        self.grid_cells = None\n",
        "        self.anchor_boxes = None\n",
        "        self.bounding_box_centers = None\n",
        "        self.detection_outputs = None\n",
        "        \n",
        "        self.is_blob_aspect_ratio = is_blob_aspect_ratio\n",
        "        \n",
        "        self.is_scale_output = is_scale_output\n",
        "        self.output_height = output_height\n",
        "          \n",
        "        if cv2.cuda.getCudaEnabledDeviceCount():    \n",
        "            self.is_cuda = True\n",
        "            print('GPU is enabled.')\n",
        "        else:\n",
        "            self.is_cuda = False\n",
        "            print('GPU is NOT enabled. OpenCV-{} will use CPU instead.'.format(cv2.__version__))\n",
        "            \n",
        "    \n",
        "    \"\"\"\n",
        "    In this method we read in a specific model and set up parameters for it.\n",
        "    \"\"\"\n",
        "    def configure_net(self, model_name=None):\n",
        "        if model_name is None:\n",
        "            model_name = self.model_name    \n",
        "        files = os.listdir(r'./net')\n",
        "        if '{}.weights'.format(model_name) not in files or '{}.cfg'.format(model_name) not in files:\n",
        "            print('''\"{mn}.weights\" or \"{mn}.cfg\" not found in \"/net\" folder. \n",
        "Check if the file is there. '''.format(mn = model_name))\n",
        "        else:\n",
        "            self.model_name = model_name\n",
        "\n",
        "            path_weights = 'net/{}.weights'.format(self.model_name)\n",
        "            path_cfg = 'net/{}.cfg'.format(self.model_name)\n",
        "            self.net = cv2.dnn.readNet(path_weights, path_cfg)\n",
        "\n",
        "            if self.is_cuda:\n",
        "                self.net.setPreferableBackend(cv2.dnn.DNN_BACKEND_CUDA)\n",
        "                self.net.setPreferableTarget(cv2.dnn.DNN_TARGET_CUDA)\n",
        "                \n",
        "            \"\"\" Fetching anchor boxes values from .cfg file. \"\"\"\n",
        "            with open('net/{}.cfg'.format(self.model_name), 'r') as f:\n",
        "                cfg = f.read().splitlines()\n",
        "                anchors_line = [line for line in cfg if 'anchors' in line][0].replace('anchors', '').replace('=', '')\n",
        "                anchors = np.array([int(num) for num in anchors_line.split(',')])\n",
        "                anchors = anchors.reshape(int(len(anchors)/6), 3, 2)[::-1]\n",
        "                self.anchors = anchors\n",
        "                \n",
        "    \n",
        "    \"\"\"\n",
        "    This method runs detection on the image. It saves all parameters of detection as class instance variables.\n",
        "    It saves ALL the detections above 0.1% accuracy from ALL grids. \n",
        "    It does not take into account given confidence and IOU threshold. \n",
        "    That will happen in draw_img('cv2.dnn.NMSBoxes') method.\n",
        "    Thanks to that we only need to run detection on image once. So changing any parameters, besides size \n",
        "    and model from keybord level on image or paused video will result in an instant change on image, \n",
        "    because we already have all the information from detection, we just need to draw them.\n",
        "    \"\"\"    \n",
        "    def detect(self, img):\n",
        "        if self.is_blob_aspect_ratio:\n",
        "            ratio_width2height = img.shape[1]/img.shape[0]\n",
        "            self.grids_per_width = round((self.input_height * ratio_width2height)/32)\n",
        "            self.input_width = self.grids_per_width*32\n",
        "        else:\n",
        "            self.input_width = self.input_height\n",
        "            self.grids_per_width = self.grids_per_height\n",
        "            \n",
        "        \"\"\" Blob is the version of the original image adjusted perfectly for the neural net. \"\"\"\n",
        "        blob = cv2.dnn.blobFromImage(img, 1 / 255, (self.input_width, self.input_height),\n",
        "                                 (0, 0, 0), swapRB=True, crop=False)\n",
        "        \n",
        "        self.net.setInput(blob)\n",
        "        output_layers_names = self.net.getUnconnectedOutLayersNames()\n",
        "        self.layerOutputs = self.net.forward(output_layers_names)\n",
        "        \n",
        "        \"\"\" After getting blob from original size image we resize it according to 'output_height', \n",
        "        so you could decide the size of output window, rather than take original size(eg.2160x3840, 120x210).\n",
        "        Then we save resized image as class instance variable.\"\"\"\n",
        "        if self.is_scale_output:\n",
        "            img = image_resize(img, height = self.output_height)\n",
        "        self.img = img\n",
        "        self.img_height, self.img_width, _ = self.img.shape\n",
        "        \n",
        "        boxes = []\n",
        "        confidences = []\n",
        "        best_class_ids = []\n",
        "        grid_cells = []\n",
        "        anchor_boxes = []\n",
        "        bounding_box_centers = []\n",
        "        detection_outputs = []\n",
        "        \n",
        "        \"\"\" Yolo algorithms give us multiple outputs. 'output' gives us detections from that output.\n",
        "        'i' gives us the number of the detection output, so we could know from which resolution grid\n",
        "        it came from (e.g. first output-13x13, second output-26x26, ...). \"\"\"\n",
        "        for i, output in enumerate(self.layerOutputs):\n",
        "            \"\"\" Yolov4 gives us detection from the smallest grids(52x52) to the biggest(13x13)\n",
        "            and rest of algorithms do the opposite. \"\"\"\n",
        "            if self.model_name == 'yolov4':\n",
        "                if i==0:\n",
        "                    i=2\n",
        "                elif i==2:\n",
        "                    i=0\n",
        "            \"\"\" 'detection' is one singular detection from all detections from one 'output'.\n",
        "            Every grid gives us 3 detections, so thanks to 'j' we can calculate from which anchor boxes \n",
        "            the detection came from. E.G 134 detection came from 134%(modulo)3=2 -> second anchor box\n",
        "            and from which grid E.G. int(134/3)=44-grid. If we have grids_per_width=13, \n",
        "            that means 44/13=3 rest 5. So fourth(3+1) row and fifth column. \"\"\"\n",
        "            for j, detection in enumerate(output):\n",
        "                \"\"\" All of the values from detection have values from 0 to 1. \"\"\"\n",
        "                scores = detection[5:]\n",
        "                best_class_id = np.argmax(scores)\n",
        "                confidence = detection[4] * scores[best_class_id]\n",
        "#                 if i==0:\n",
        "#                     print(j%3, self.anchors[i][j % 3], detection[:5], scores[best_class_id], \n",
        "#                           self.classes[best_class_id])\n",
        "\n",
        "                if confidence > 0.001:\n",
        "                    anchor_box = self.anchors[i][j % 3]\n",
        "                    \"\"\" self.grids_per_width * 2 ** i-> 13 * 2 ** (0,1,2), so 13,26,52. \"\"\"\n",
        "                    grid_cell = [int(j / 3) % (self.grids_per_width * 2 ** i),\n",
        "                                 int(j / (self.grids_per_width * 3 * 2 ** i))]\n",
        "                    \n",
        "                    center_x = round(detection[0] * self.img_width)\n",
        "                    center_y = round(detection[1] * self.img_height)\n",
        "                    w = round(detection[2] * self.img_width)\n",
        "                    h = round(detection[3] * self.img_height)\n",
        "                    x = round(center_x - w / 2)\n",
        "                    y = round(center_y - h / 2)\n",
        "\n",
        "                    boxes.append([x, y, w, h])\n",
        "                    confidences.append((float(confidence)))\n",
        "                    best_class_ids.append(best_class_id)\n",
        "                    grid_cells.append(grid_cell)\n",
        "                    anchor_boxes.append(anchor_box)\n",
        "                    bounding_box_centers.append((center_x, center_y))\n",
        "                    \"\"\" For scaling to proper grid(13,26,52,...). \"\"\"\n",
        "                    detection_outputs.append(i)\n",
        "            \n",
        "        self.boxes = boxes\n",
        "        self.confidences = confidences\n",
        "        self.best_class_ids = best_class_ids\n",
        "        self.grid_cells = grid_cells\n",
        "        self.anchor_boxes = anchor_boxes\n",
        "        self.bounding_box_centers = bounding_box_centers\n",
        "        self.detection_outputs = detection_outputs\n",
        "        \n",
        "    \"\"\"\n",
        "    This method draws all accessories according to parameters.\n",
        "    \"\"\"\n",
        "    def draw_img(self):\n",
        "        img = self.img.copy()\n",
        "        if self.show_text_left:\n",
        "            cv2.putText(img, \"IOU:  {0:.0%}\".format(self.IOU_threshold), (20, 40), self.font, 3, (0, 0, 255), 3)\n",
        "            cv2.putText(img, \"CONF: {0:.0%}\".format(self.MIN_confidence), (20, 80), self.font, 3, (255, 0, 0), 3)\n",
        "        \n",
        "        \"\"\" This method uses MIN_confidence and IOU_threshold to choose right indexes of boxes to show.\n",
        "        E.G. detection found 40 objects on the image, but some of them have low confidence\n",
        "        and some of them seems to show the same object(IOU). So the method decides to only show\n",
        "        objects with indexes i=3,11,18. 'c' is enumerator. \"\"\"\n",
        "        indexes = cv2.dnn.NMSBoxes(self.boxes, self.confidences, self.MIN_confidence, self.IOU_threshold)\n",
        "        if len(indexes) > 0:\n",
        "            for c, i in enumerate(indexes.flatten()):\n",
        "                x, y, w, h = self.boxes[i]\n",
        "                label = str(self.classes[self.best_class_ids[i]])\n",
        "                confidence = self.confidences[i]\n",
        "                color = self.colors[c%len(self.colors)]\n",
        "                cv2.rectangle(img, (x, y), (x + w, y + h), color, 2)\n",
        "                if self.show_text_on_box:\n",
        "                    cv2.putText(img, '{}.{} {:.0%}'.format(c+1, label, confidence), (x+2, y-5), \n",
        "                                self.font, 2, color, 3)\n",
        "                elif self.show_text_left:\n",
        "                    cv2.putText(img, '{}'.format(c+1), (x+2, y-5), self.font, 2, color, 3)\n",
        "\n",
        "                num_of_grids_w = (self.grids_per_width * 2 ** self.detection_outputs[i])\n",
        "                num_of_grids_h = (self.grids_per_height * 2 ** self.detection_outputs[i])\n",
        "                \"\"\" OpenCV draws rectangles using left top corner and right down corner parameters. \"\"\"\n",
        "                grid_corner_x= int(round(self.grid_cells[i][0] * self.img_width / num_of_grids_w))\n",
        "                grid_corner_y = int(round(self.grid_cells[i][1] * self.img_height / num_of_grids_h))\n",
        "                grid_w = round(self.img_width / num_of_grids_w)\n",
        "                grid_h = round(self.img_height / num_of_grids_h)\n",
        "                if self.grid_show:\n",
        "                    cv2.rectangle(img, (grid_corner_x, grid_corner_y), (grid_corner_x+ grid_w, grid_corner_y + grid_h), \n",
        "                                  color, int(4 / 2 ** self.detection_outputs[i]))\n",
        "                    cv2.circle(img, (self.bounding_box_centers[i]), 3, color, 4)\n",
        "\n",
        "                ab_center_x = round(grid_corner_x+ grid_w * 0.5)\n",
        "                ab_center_y = round(grid_corner_y + grid_h * 0.5)\n",
        "                ab_width = self.anchor_boxes[i][0] * self.img_width / self.input_width\n",
        "                ab_height = self.anchor_boxes[i][1] * self.img_height / self.input_height\n",
        "                if self.anchor_box_show:\n",
        "                    cv2.rectangle(img, (round(ab_center_x - 0.5 * ab_width),\n",
        "                                        round(ab_center_y - 0.5 * ab_height)),\n",
        "                                       (round(ab_center_x + 0.5 * ab_width), \n",
        "                                        round(ab_center_y + 0.5*ab_height)), \n",
        "                                       color, int(4 / 2 ** self.detection_outputs[i]))\n",
        "                    cv2.rectangle(img, (round(ab_center_x - 0.5 * ab_width),\n",
        "                                        round(ab_center_y - 0.5 * ab_height)),\n",
        "                                       (round(ab_center_x + 0.5 * ab_width), \n",
        "                                        round(ab_center_y + 0.5*ab_height)), \n",
        "                                       (255,255,255), 1)\n",
        "                    text = '{}:{} {:.0%} {}({})'.format(c+1, label, confidence, self.anchor_boxes[i], \n",
        "                                    self.detection_outputs[i])\n",
        "                else:\n",
        "                    text = '{}:{} {:.0%}'.format(c+1, label, confidence)\n",
        "                if self.show_text_left:\n",
        "                    cv2.putText(img, text, (20, 210 + 30 * c),self.font, 2, color, 3)\n",
        "        if self.show_text_left:    \n",
        "            cv2.putText(img, '{mn} {iw}x{ih}'.format(mn=self.model_name, iw=self.input_width, \n",
        "                        ih=self.input_height), (20, 110),self.font, 2, (255,0,255), 3)\n",
        "            cv2.putText(img, 'FPS: {:.2f}'.format(self.FPS), (20, 140),\n",
        "                    self.font, 2, (255,0,255), 3)\n",
        "            cv2.putText(img, 'REC:{}'.format('ON' if self.is_recording else \"OFF\"), (20, 170),\n",
        "            self.font, 2, ((0, 255, 0) if self.is_recording else (0, 0, 255)), 3)\n",
        "\n",
        "        self.img_with_drawings = img\n",
        "        cv2.imshow('Detection', img)\n",
        "        \n",
        "    \"\"\" \n",
        "    When pressed 'p' image will be saved to specific location.\n",
        "    \"\"\"\n",
        "    def save_img(self):\n",
        "        img_name = self.img_name\n",
        "        if len(img_name) == 0: \n",
        "            img_name = 'camera'\n",
        "        time_of_save = time.strftime('%d_%H%M%S', time.localtime())\n",
        "        cv2.imwrite('detections/{}_{}.png'.format(img_name, time_of_save), \n",
        "                   self.img_with_drawings)    \n",
        "    \n",
        "    \"\"\" \n",
        "    Keyboard input handling. \n",
        "    \"\"\"\n",
        "    def keyboard(self, key, img):\n",
        "        if key == ord('q'):\n",
        "            return 'quit'\n",
        "        elif key == 32: # 'Space'\n",
        "            return 'pause-unpause'\n",
        "        elif key == ord('3'):\n",
        "            self.configure_net('yolov3')\n",
        "            start_time = time.time()\n",
        "            self.detect(img)\n",
        "            self.FPS = 1/(time.time() - start_time)\n",
        "            self.draw_img()\n",
        "        elif key == ord('#'):\n",
        "            self.configure_net('yolov3-tiny')\n",
        "            start_time = time.time()\n",
        "            self.detect(img)\n",
        "            self.FPS = 1/(time.time() - start_time)\n",
        "            self.draw_img()\n",
        "        elif key == ord('4'):\n",
        "            self.configure_net('yolov4')\n",
        "            start_time = time.time()\n",
        "            self.detect(img)\n",
        "            self.FPS = 1/(time.time() - start_time)\n",
        "            self.draw_img()\n",
        "        elif key == ord('$'):\n",
        "            self.configure_net('yolov4-tiny')\n",
        "            start_time = time.time()\n",
        "            self.detect(img)\n",
        "            self.FPS = 1/(time.time() - start_time)\n",
        "            self.draw_img()      \n",
        "        elif key == 93: # ']'\n",
        "            self.grids_per_height = min(self.grids_per_height + 1, 1024)\n",
        "            self.input_height = self.grids_per_height * 32\n",
        "            self.detect(img)\n",
        "            self.draw_img()\n",
        "        elif key == 91: # '['    \n",
        "            self.grids_per_height = max(self.grids_per_height - 1, 1)\n",
        "            self.input_height = self.grids_per_height * 32\n",
        "            self.detect(img)\n",
        "            self.draw_img()\n",
        "        elif key == ord('r'):\n",
        "            self.is_blob_aspect_ratio = not self.is_blob_aspect_ratio\n",
        "            self.detect(img)\n",
        "            self.draw_img()    \n",
        "        elif key == ord('t'):\n",
        "            self.show_text_on_box = not self.show_text_on_box\n",
        "            self.draw_img() \n",
        "        elif key == ord('T'):\n",
        "            self.show_text_left = not self.show_text_left\n",
        "            self.draw_img() \n",
        "        elif key == ord('p'):\n",
        "            self.save_img()\n",
        "        elif key == ord('v'):\n",
        "            self.is_recording = not self.is_recording\n",
        "        elif key == ord('w'):\n",
        "            self.IOU_threshold = min(self.IOU_threshold + 0.01, 1)\n",
        "            self.draw_img()\n",
        "        elif key == ord('s'):\n",
        "            self.IOU_threshold = max(self.IOU_threshold - 0.01, 0)\n",
        "            self.draw_img()\n",
        "        elif key == ord('d'):\n",
        "            self.MIN_confidence = min(self.MIN_confidence + 0.01, 1)\n",
        "            self.draw_img()\n",
        "        elif key == ord('a'):\n",
        "            self.MIN_confidence = max(self.MIN_confidence - 0.01, 0)\n",
        "            self.draw_img()\n",
        "        elif key == ord('W'):\n",
        "            self.IOU_threshold = min(self.IOU_threshold + 0.1, 1)\n",
        "            self.draw_img()\n",
        "        elif key == ord('S'):\n",
        "            self.IOU_threshold = max(self.IOU_threshold - 0.1, 0)\n",
        "            self.draw_img()\n",
        "        elif key == ord('D'):\n",
        "            self.MIN_confidence = min(self.MIN_confidence + 0.1, 1)\n",
        "            self.draw_img()\n",
        "        elif key == ord('A'):\n",
        "            self.MIN_confidence = max(self.MIN_confidence - 0.1, 0)\n",
        "            self.draw_img()\n",
        "        elif key == ord('g'):\n",
        "            self.grid_show = not self.grid_show\n",
        "            self.draw_img()\n",
        "        elif key == ord('b'):\n",
        "            self.anchor_box_show = not self.anchor_box_show\n",
        "            self.draw_img()\n",
        " \n",
        "\"\"\" Resizing image. \"\"\"\n",
        "def image_resize(image, width = None, height = None, inter = cv2.INTER_AREA):\n",
        "    dim = None\n",
        "    (h, w) = image.shape[:2]\n",
        "    if width is None and height is None:\n",
        "        return image\n",
        "    if width is None:\n",
        "        r = height / float(h)\n",
        "        dim = (int(w * r), height)\n",
        "    else:\n",
        "        r = width / float(w)\n",
        "        dim = (width, int(h * r))\n",
        "    resized = cv2.resize(image, dim, interpolation = inter)\n",
        "    return resized\n",
        "\n",
        "def video_recording(self, output_path):\n",
        "    self.video_record =  cv2.VideoWriter(output_path, cv2.VideoWriter_fourcc(*'MJPG'),\n",
        "                               self.FPS, (self.img_width, self.img_height))"
      ],
      "id": "1hRvuGiuKh-f"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "run_control": {
          "marked": false
        },
        "scrolled": true,
        "id": "J5CXl03tKh-x"
      },
      "outputs": [],
      "source": [
        "\"\"\" Run detection on video from your computer or camera. \"\"\"\n",
        "Det = Detection(model_name='yolov4-tiny', input_height=320, output_height=700, is_blob_aspect_ratio=False)\n",
        "Det.configure_net()\n",
        "\n",
        "\"\"\" For capturing camera videos enter '0', \n",
        "or '1,2,3,...' if you have multiple cameras connected to your computer. \"\"\"\n",
        "path_to_folder_input = r'data'\n",
        "video_source_name = 'NY.wmv'\n",
        "\n",
        "url   = \"https://www.youtube.com/watch?v=kf4brQ2g5FI\"\n",
        "video = pafy.new(url)\n",
        "best  = video.getbest(preftype=\"mp4\")\n",
        "capture = cv2.VideoCapture(best.url)\n",
        "\"\"\" CHOOSE \"\"\"\n",
        "#video_source_path = r'{}/{}'.format(path_to_folder_input, video_source_name) # video file\n",
        "#video_source_path = best.url # web video\n",
        "video_source_path = 0 # CAMERA\n",
        "\n",
        "video = cv2.VideoCapture(video_source_path) # for video file\n",
        "\n",
        "print('Video image size {}x{}.'.format(int(video.get(cv2.CAP_PROP_FRAME_WIDTH)),\n",
        "                                 int(video.get(cv2.CAP_PROP_FRAME_HEIGHT))))\n",
        "if not int(video.get(cv2.CAP_PROP_FRAME_WIDTH)):\n",
        "    print(\"\"\"You probably misspelled the file name or the file does not exist.\n",
        "Or you forgot to plug your camera in.\"\"\")\n",
        "    \n",
        "    \n",
        "\" You could set up the name you desire or leave variable empty, then name of the source will be used. \"    \n",
        "video_save_name = '' \n",
        "if len(video_save_name) == 0:\n",
        "    if video_source_path == 0:\n",
        "        video_save_name = 'camera'\n",
        "    elif video_source_path == best.url:\n",
        "        video_save_name = 'web'\n",
        "    else:\n",
        "        video_save_name = video_source_name.split('.')[0]\n",
        "\n",
        "Det.img_name = video_save_name\n",
        "\n",
        "\" Few runs on the net to get FPS for save file, or you could set it manually. \"\n",
        "FPS_of_source_video = video.get(cv2.CAP_PROP_FPS) \n",
        "for i in range(2):\n",
        "    start_time = time.time()\n",
        "    check, img = video.read()\n",
        "    Det.detect(img)\n",
        "    Det.draw_img()\n",
        "    Det.FPS = 1/(time.time() - start_time)\n",
        "\"\"\" CHOOSE \"\"\"\n",
        "FPS_of_save_video = FPS_of_source_video # Not advised when source of the video is camera\n",
        "#FPS_of_save_video = Det.FPS \n",
        "    \n",
        "time_of_save = time.strftime('%d_%H%M%S', time.localtime())\n",
        "output_path = 'detections/{}_{}.mp4'.format(video_save_name, time_of_save)\n",
        "video_record = cv2.VideoWriter(output_path, cv2.VideoWriter_fourcc(*'MJPG'),\n",
        "                               FPS_of_save_video, (Det.img_width, Det.img_height))\n",
        "\n",
        "\n",
        "run_detection = True\n",
        "while run_detection:\n",
        "    try:\n",
        "        start_time = time.time()\n",
        "        check, img = video.read()\n",
        "        if type(video_source_path) is int:\n",
        "            img = cv2.flip(img, 1)\n",
        "        \n",
        "        \n",
        "        Det.detect(img)\n",
        "        Det.draw_img()\n",
        "        \n",
        "        if Det.is_recording:\n",
        "            Det.is_any_frame_recorded = True\n",
        "            video_record.write(Det.img_with_drawings)\n",
        "\n",
        "        \"\"\" If any keyboard key has been pressed while the program is running, \n",
        "        OpenCV will capture it and save it as 'key' variable.\n",
        "        If no key has been pressed key=-1. \"\"\"\n",
        "        key = cv2.waitKey(1) \n",
        "        if key != -1:\n",
        "            key_response = Det.keyboard(key, img)\n",
        "            if key_response == 'quit': \n",
        "                run_detection = False\n",
        "            elif key_response == 'pause-unpause':\n",
        "                while True:\n",
        "                    \" cv2.waitKey(0) will wait until the key is pressed. \"\n",
        "                    key = cv2.waitKey(0)\n",
        "                    key_response = Det.keyboard(key, img)\n",
        "                    if key_response == 'quit':\n",
        "                        run_detection = False\n",
        "                        break\n",
        "                    elif key_response == 'pause-unpause':\n",
        "                        break\n",
        "                    if cv2.getWindowProperty('Detection',cv2.WND_PROP_VISIBLE) < 1:        \n",
        "                        run_detection = False\n",
        "                        break \n",
        "\n",
        "        if cv2.getWindowProperty('Detection',cv2.WND_PROP_VISIBLE) < 1:        \n",
        "            run_detection = False \n",
        "        Det.FPS = 1/(time.time() - start_time)\n",
        "        \n",
        "    except: \n",
        "        print(traceback.format_exc())\n",
        "        video.release()\n",
        "        video_record.release()\n",
        "        if not Det.is_any_frame_recorded:\n",
        "            os.remove(output_path)\n",
        "        cv2.destroyAllWindows()\n",
        "        break\n",
        "video.release()\n",
        "video_record.release()\n",
        "if not Det.is_any_frame_recorded:\n",
        "    os.remove(output_path)\n",
        "cv2.destroyAllWindows()"
      ],
      "id": "J5CXl03tKh-x"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "Us-Rp5HOKh-4"
      },
      "outputs": [],
      "source": [
        "\"\"\" Run detection on image from your computer. \"\"\"\n",
        "Det = Detection(model_name='yolov4', input_height=320, output_height=700)\n",
        "Det.configure_net()\n",
        "path_to_folder_input = r'data'\n",
        "img_name_with_extension = 'cat4k.jpg'\n",
        "Det.img_name = ''.join(img_name_with_extension.split('.')[:-1])\n",
        "try:\n",
        "    img = cv2.imread(r'{}\\{}'.format(path_to_folder_input, img_name_with_extension))\n",
        "    print('Image size {}.'.format(img.shape[:2]))\n",
        "    if not int(img.shape[0]):\n",
        "        print(\"You probably misspelled the file name or the file does not exist.\")\n",
        "\n",
        "    start_time = time.time()\n",
        "    Det.detect(img)\n",
        "    Det.FPS = 1/(time.time() - start_time)\n",
        "    Det.draw_img()\n",
        "\n",
        "    while True:\n",
        "        Det.is_pause = True\n",
        "        key = cv2.waitKey(0)\n",
        "        key = Det.keyboard(key, img)\n",
        "        if key == 'quit':\n",
        "            run_detection = False\n",
        "            break\n",
        "        if cv2.getWindowProperty('Detection',cv2.WND_PROP_VISIBLE) < 1:        \n",
        "            break \n",
        "\n",
        "except: \n",
        "    print(traceback.format_exc())\n",
        "    cv2.destroyAllWindows()\n",
        "    \n",
        "cv2.destroyAllWindows()"
      ],
      "id": "Us-Rp5HOKh-4"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cWd3SVFwKh-8"
      },
      "outputs": [],
      "source": [
        " \"\"\" Run detection on image from the web. \"\"\"\n",
        "Det = Detection(model_name='yolov4', input_height=320, output_height=700)\n",
        "Det.configure_net()\n",
        "url_to_img = '''\n",
        "https://64.media.tumblr.com/91ec579b616e006c1d689c51f763d6ce/tumblr_oklmipESuY1ucobdyo1_500.jpg\n",
        "'''\n",
        "img_save_name = ''\n",
        "if len(img_save_name)>0 and img_name:\n",
        "    Det.img_name = img_save_name\n",
        "elif any(char in url_to_img.replace(\"\\n\", \"\").split('/')[-1] for char in ['#','%','&','*',':','<','>','?']):\n",
        "    Det.img_name = 'web_img'\n",
        "else:\n",
        "    Det.img_name = url_to_img.replace(\"\\n\", \"\").split('/')[-1]\n",
        "\n",
        "try:\n",
        "    req = Request(url_to_img, headers={'User-Agent': 'Mozilla/5.0'})\n",
        "    req = urlopen(req).read()\n",
        "    arr = np.asarray(bytearray(req), dtype=np.uint8)\n",
        "    img = cv2.imdecode(arr, -1)\n",
        "    print('Image size {}.'.format(img.shape[:2]))\n",
        "    if not int(img.shape[0]):\n",
        "        print(\"You probably misspelled the file name or the file does not exist.\")\n",
        "\n",
        "    start_time = time.time()\n",
        "    Det.detect(img)\n",
        "    Det.FPS = 1/(time.time() - start_time)\n",
        "    Det.draw_img()\n",
        "\n",
        "    while True:\n",
        "        Det.is_pause = True\n",
        "        key = cv2.waitKey(0)\n",
        "        key = Det.keyboard(key, img)\n",
        "        if key == 'quit':\n",
        "            run_detection = False\n",
        "            break\n",
        "        if cv2.getWindowProperty('Detection',cv2.WND_PROP_VISIBLE) < 1:        \n",
        "            break             \n",
        "except urllib.error.HTTPError:\n",
        "    print(\"This file probably does not exist(check if you paste it correctly) or it is protected.\")\n",
        "    print(traceback.format_exc())   \n",
        "    cv2.destroyAllWindows()\n",
        "except: \n",
        "    print(traceback.format_exc())\n",
        "    cv2.destroyAllWindows()\n",
        "    \n",
        "cv2.destroyAllWindows()"
      ],
      "id": "cWd3SVFwKh-8"
    }
  ],
  "metadata": {
    "hide_input": false,
    "kernelspec": {
      "display_name": "yolo_tutorial",
      "language": "python",
      "name": "yolo_tutorial"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}